{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaHWZh5b0tQQ70WpQim141",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingtongxiong/MLCnotebooks/blob/xytExercise/2_4_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m  pip install mlc-ai-nightly -f https://mlc.ai/wheels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XWyPBdSPPsP",
        "outputId": "a69f6fc8-c5e1-4fd8-c494-4f9bdf06ff27"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://mlc.ai/wheels\n",
            "Collecting mlc-ai-nightly\n",
            "  Downloading https://github.com/mlc-ai/utils/releases/download/v0.9.dev0/mlc_ai_nightly-0.9.dev2227%2Bg06c0ef3be-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 45.5 MB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.7.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (4.4.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (22.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (5.4.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlc-ai-nightly) (1.21.6)\n",
            "Collecting synr==0.6.0\n",
            "  Downloading synr-0.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: synr, mlc-ai-nightly\n",
            "Successfully installed mlc-ai-nightly-0.9.dev2227+g06c0ef3be synr-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "import numpy as np\n",
        "import tvm\n",
        "from tvm.ir.module import IRModule\n",
        "from tvm.script import tir as T"
      ],
      "metadata": {
        "id": "dTWbRapYPLWW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init data\n",
        "a = np.arange(16).reshape(4, 4)\n",
        "b = np.arange(16, 0, -1).reshape(4, 4)"
      ],
      "metadata": {
        "id": "VsY95ffRQDuG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# low-level numpy version add\n",
        "def lnumpy_add(a: np.ndarray, b: np.ndarray, c: np.ndarray):\n",
        "  for i in range(4):\n",
        "    for j in range(4):\n",
        "      c[i, j] = a[i, j] + b[i, j]\n",
        "\n",
        "c_lnumpy = np.empty((4, 4), dtype=np.int64)\n",
        "lnumpy_add(a, b, c_lnumpy)\n",
        "c_lnumpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UoV6TiaPZrG",
        "outputId": "38635e41-f746-4db3-ad60-fc7189e2f197"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer[(4, 4), \"int64\"],\n",
        "          B: T.Buffer[(4, 4), \"int64\"],\n",
        "          C: T.Buffer[(4, 4), \"int64\"]):\n",
        "    T.func_attr({\"global_symbol\": \"add\"})\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vi, vj]\n",
        "\n",
        "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
        "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c_lnumpy, rtol=1e-5)"
      ],
      "metadata": {
        "id": "rqTJwuZdQCvv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 练习1: 广播加法"
      ],
      "metadata": {
        "id": "tsdvrxduRpce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init data\n",
        "a = np.arange(16).reshape(4, 4)\n",
        "b = np.arange(4, 0, -1).reshape(4)"
      ],
      "metadata": {
        "id": "ZPLXvovBRUD6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaSSWtc6SG8G",
        "outputId": "0e25e545-3c58-49ee-e135-4a71cb9105ca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  1,  2,  3],\n",
              "       [ 4,  5,  6,  7],\n",
              "       [ 8,  9, 10, 11],\n",
              "       [12, 13, 14, 15]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuhE4pyISIHR",
        "outputId": "0df4255f-263c-40a2-80fa-2c2d7652ceeb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 3, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy version\n",
        "c_np = a + b\n",
        "c_np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GilQD0MBSJBe",
        "outputId": "64a7172e-ae3e-4dc9-a6ad-75a904093112"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  4,  4,  4],\n",
              "       [ 8,  8,  8,  8],\n",
              "       [12, 12, 12, 12],\n",
              "       [16, 16, 16, 16]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyAdd:\n",
        "  @T.prim_func\n",
        "  def add(A: T.Buffer[(4, 4), \"int64\"],\n",
        "          B: T.Buffer[(4,), \"int64\"],\n",
        "          C: T.Buffer[(4, 4), \"int64\"]):\n",
        "    T.func_attr({\"global_symbol\": \"add\", \"tir.noalias\": True})\n",
        "    for i, j in T.grid(4, 4):\n",
        "      with T.block(\"C\"):\n",
        "        vi = T.axis.spatial(4, i)\n",
        "        vj = T.axis.spatial(4, j)\n",
        "        C[vi, vj] = A[vi, vj] + B[vj]\n",
        "\n",
        "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(a)\n",
        "b_tvm = tvm.nd.array(b)\n",
        "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
        "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
        "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
      ],
      "metadata": {
        "id": "wKW30xUuSOpC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 练习2: 二维卷积"
      ],
      "metadata": {
        "id": "amjGhaPzY_h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, CI, H, W, CO, K = 1, 1, 8, 8, 2, 3\n",
        "OUT_H, OUT_W = H - K + 1, W - K + 1\n",
        "data = np.arange(N * CI * H * W).reshape(N, CI, H, W)\n",
        "weight = np.arange(CO * CI * K * K).reshape(CO, CI, K, K)"
      ],
      "metadata": {
        "id": "6a1TdlbvUyQq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "data_torch = torch.Tensor(data)\n",
        "weight_torch = torch.Tensor(weight)\n",
        "conv_torch = torch.nn.functional.conv2d(data_torch, weight_torch)\n",
        "conv_torch = conv_torch.numpy().astype(np.int64)\n",
        "conv_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHS2WDtGaikp",
        "outputId": "96921c16-6cba-43c9-c5b6-654dde5679b4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 474,  510,  546,  582,  618,  654],\n",
              "         [ 762,  798,  834,  870,  906,  942],\n",
              "         [1050, 1086, 1122, 1158, 1194, 1230],\n",
              "         [1338, 1374, 1410, 1446, 1482, 1518],\n",
              "         [1626, 1662, 1698, 1734, 1770, 1806],\n",
              "         [1914, 1950, 1986, 2022, 2058, 2094]],\n",
              "\n",
              "        [[1203, 1320, 1437, 1554, 1671, 1788],\n",
              "         [2139, 2256, 2373, 2490, 2607, 2724],\n",
              "         [3075, 3192, 3309, 3426, 3543, 3660],\n",
              "         [4011, 4128, 4245, 4362, 4479, 4596],\n",
              "         [4947, 5064, 5181, 5298, 5415, 5532],\n",
              "         [5883, 6000, 6117, 6234, 6351, 6468]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_torch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncvok2W3cTDM",
        "outputId": "e20bcad9-6f97-402a-a189-4902f60a9173"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, 6, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# low-level numpy implementation\n",
        "def lnumpy_conv2d(data: np.ndarray, weight: np.ndarray):\n",
        "  N, CI, H, W = data.shape\n",
        "  CO, CI, K, K = weight.shape\n",
        "  OUT_H, OUT_W = H - K + 1, W - K + 1\n",
        "  output = np.zeros((N, CO, OUT_H, OUT_W))\n",
        "  for i in range(N):\n",
        "    for j in range(CO):\n",
        "      for i1 in range(OUT_H):\n",
        "        for j1 in range(OUT_W):\n",
        "          for ci in range(CI):\n",
        "            for i11 in range(K):\n",
        "              for j11 in range(K):\n",
        "                output[i, j, i1, j1] += weight[j, ci, i11, j11] * data[i, ci, i1 + i11, j1 + j11]\n",
        "  \n",
        "\n",
        "  return output\n",
        "\n",
        "output_numpy = lnumpy_conv2d(data, weight)\n",
        "np.testing.assert_allclose(output_numpy, conv_torch, rtol=1e-5)\n",
        "\n"
      ],
      "metadata": {
        "id": "QP89hwL8a-Mc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A:(N, CI, H, W)\n",
        "# B:(CO, CI, K, K)\n",
        "# C: (N, CO, H - K + 1, W - K + 1)\n",
        "# strides = 1 and padding = 0\n",
        "@tvm.script.ir_module\n",
        "class MyConv:\n",
        "  @T.prim_func\n",
        "  def conv(data: T.Buffer[(1, 1, 8, 8), \"int64\"],\n",
        "           weight: T.Buffer[(2, 1, 3, 3), \"int64\"],\n",
        "           output: T.Buffer[(1, 2, 6, 6), \"int64\"]):\n",
        "    T.func_attr({\"global_symbol\": \"conv\", \"tir.noalias\": True})\n",
        "    for i, j, i1, j1, ci, i11, j11 in T.grid(1, 2, 6, 6, 1, 3, 3):\n",
        "      with T.block(\"C\"):\n",
        "        vi, vj, vi1, vj1 = T.axis.remap(\"SSSS\", (i, j, i1, j1))\n",
        "        vci, vi11, vj11 = T.axis.remap(\"RRR\", (ci, i11, j11))\n",
        "        with T.init():\n",
        "          output[vi, vj, vi1, vj1] = T.int64(0)\n",
        "        output[vi, vj, vi1, vj1] += weight[vj, vci, vi11, vj11] * data[vi, vci, vi1 + vi11, vj1 + vj11]\n",
        "\n",
        "\n",
        "rt_lib = tvm.build(MyConv, target=\"llvm\")\n",
        "data_tvm = tvm.nd.array(data)\n",
        "weight_tvm = tvm.nd.array(weight)\n",
        "conv_tvm = tvm.nd.array(np.empty((N, CO, OUT_H, OUT_W), dtype=np.int64))\n",
        "rt_lib[\"conv\"](data_tvm, weight_tvm, conv_tvm)\n",
        "# # print(conv_tvm)\n",
        "np.testing.assert_allclose(conv_tvm.numpy(), conv_torch, rtol=1e-5)"
      ],
      "metadata": {
        "id": "_XBbc22ZbZNJ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 练习3: 变化批量矩阵乘法程序"
      ],
      "metadata": {
        "id": "beGHWgq3oHEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tvm.script.ir_module\n",
        "class MyBmmRelu:\n",
        "  @T.prim_func\n",
        "  def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"],\n",
        "               B: T.Buffer[(16, 128, 128), \"float32\"],\n",
        "               C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
        "    T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
        "    Y = T.alloc_buffer((16, 128, 128), dtype=\"float32\")\n",
        "    for n, i, j, k in T.grid(16, 128, 128, 128):\n",
        "      with T.block(\"Y\"):\n",
        "        vn, vi, vj, vk = T.axis.remap(\"SSSR\", (n, i, j, k))\n",
        "        with T.init():\n",
        "          Y[vn, vi, vj] = T.float32(0)\n",
        "        Y[vn, vi, vj] += A[vn, vi, vk] * B[vn, vk, vj]\n",
        "    \n",
        "    for n, i, j in T.grid(16, 128, 128):\n",
        "      with T.block(\"C\"):\n",
        "        vn, vi, vj = T.axis.remap(\"SSS\", (n, i, j))\n",
        "        C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "r-Pp2BmDja86"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sch = tvm.tir.Schedule(MyBmmRelu)\n",
        "# TODO: transformations\n",
        "# Hints: you can use\n",
        "# `IPython.display.Code(sch.mod.script(), language=\"python\")`\n",
        "# or `print(sch.mod.script())`\n",
        "# to show the current program at any time during the transformation.\n",
        "\n",
        "# Step 1. Get blocks\n",
        "Y = sch.get_block(\"Y\", func_name=\"bmm_relu\")\n",
        "\n",
        "# Step 2. Get loops\n",
        "n, i, j, k = sch.get_loops(Y)\n",
        "sch.parallel(n)\n",
        "\n",
        "# Step 3. Organize the loops\n",
        "j0, j1 = sch.split(j, factors=[None, 8])\n",
        "sch.reorder(j0, k, j1)\n",
        "C = sch.get_block(\"C\", func_name=\"bmm_relu\")\n",
        "sch.reverse_compute_at(C, j0)\n",
        "\n",
        "# Step 4. decompose reduction\n",
        "Y_init = sch.decompose_reduction(Y, k)\n",
        "n, i, j_0, j_1_init = sch.get_loops(Y_init)\n",
        "_, _, _, ax0 = sch.get_loops(C)\n",
        "Y_update = sch.get_block(\"Y_update\", func_name=\"bmm_relu\")\n",
        "_, _, _, k, j_1 = sch.get_loops(Y_update)\n",
        "k0, k1 = sch.split(k, factors=[None, 4])\n",
        "\n",
        "# Step 5. vectorize / parallel / unroll\n",
        "sch.vectorize(j_1_init)\n",
        "sch.vectorize(ax0)\n",
        "sch.unroll(k1)\n",
        "\n",
        "\n",
        "IPython.display.Code(sch.mod.script(), language=\"python\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "RInywzJgpgUK",
        "outputId": "a8ab93e2-da33-4b2e-d92f-a06a6fed2411"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "@tvm.script.ir_module\n",
              "class Module:\n",
              "    @T.prim_func\n",
              "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
              "        # function attr dict\n",
              "        T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
              "        # body\n",
              "        # with T.block(\"root\")\n",
              "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
              "        for n in T.parallel(16):\n",
              "            for i, j_0 in T.grid(128, 16):\n",
              "                for j_1_init in T.vectorized(8):\n",
              "                    with T.block(\"Y_init\"):\n",
              "                        vn, vi = T.axis.remap(\"SS\", [n, i])\n",
              "                        vj = T.axis.spatial(128, j_0 * 8 + j_1_init)\n",
              "                        T.reads()\n",
              "                        T.writes(Y[vn, vi, vj])\n",
              "                        Y[vn, vi, vj] = T.float32(0)\n",
              "                for k_0 in T.serial(32):\n",
              "                    for k_1 in T.unroll(4):\n",
              "                        for j_1 in T.serial(8):\n",
              "                            with T.block(\"Y_update\"):\n",
              "                                vn, vi = T.axis.remap(\"SS\", [n, i])\n",
              "                                vj = T.axis.spatial(128, j_0 * 8 + j_1)\n",
              "                                vk = T.axis.reduce(128, k_0 * 4 + k_1)\n",
              "                                T.reads(Y[vn, vi, vj], A[vn, vi, vk], B[vn, vk, vj])\n",
              "                                T.writes(Y[vn, vi, vj])\n",
              "                                Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
              "                for ax0 in T.vectorized(8):\n",
              "                    with T.block(\"C\"):\n",
              "                        vn, vi = T.axis.remap(\"SS\", [n, i])\n",
              "                        vj = T.axis.spatial(128, j_0 * 8 + ax0)\n",
              "                        T.reads(Y[vn, vi, vj])\n",
              "                        T.writes(C[vn, vi, vj])\n",
              "                        C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
              "    "
            ],
            "text/html": [
              "<style>.output_html .hll { background-color: #ffffcc }\n",
              ".output_html  { background: #f8f8f8; }\n",
              ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
              ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
              ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
              ".output_html .o { color: #666666 } /* Operator */\n",
              ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
              ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
              ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
              ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
              ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
              ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
              ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
              ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
              ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
              ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
              ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
              ".output_html .go { color: #888888 } /* Generic.Output */\n",
              ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
              ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
              ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
              ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
              ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
              ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
              ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
              ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
              ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
              ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
              ".output_html .m { color: #666666 } /* Literal.Number */\n",
              ".output_html .s { color: #BA2121 } /* Literal.String */\n",
              ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
              ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
              ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
              ".output_html .no { color: #880000 } /* Name.Constant */\n",
              ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
              ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
              ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
              ".output_html .nf { color: #0000FF } /* Name.Function */\n",
              ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
              ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
              ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
              ".output_html .nv { color: #19177C } /* Name.Variable */\n",
              ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
              ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
              ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
              ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
              ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
              ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
              ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
              ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
              ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
              ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
              ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
              ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
              ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
              ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
              ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
              ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
              ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
              ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
              ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
              ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
              ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
              ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
              ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
              ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
              ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
              ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
              ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
              "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
              "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
              "    <span class=\"k\">def</span> <span class=\"nf\">bmm_relu</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">C</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">])</span> <span class=\"o\">-&gt;</span> <span class=\"kc\">None</span><span class=\"p\">:</span>\n",
              "        <span class=\"c1\"># function attr dict</span>\n",
              "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;bmm_relu&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">})</span>\n",
              "        <span class=\"c1\"># body</span>\n",
              "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
              "        <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">([</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)</span>\n",
              "        <span class=\"k\">for</span> <span class=\"n\">n</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">parallel</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">):</span>\n",
              "            <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">16</span><span class=\"p\">):</span>\n",
              "                <span class=\"k\">for</span> <span class=\"n\">j_1_init</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">vectorized</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">):</span>\n",
              "                    <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y_init&quot;</span><span class=\"p\">):</span>\n",
              "                        <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
              "                        <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j_1_init</span><span class=\"p\">)</span>\n",
              "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">()</span>\n",
              "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                        <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
              "                <span class=\"k\">for</span> <span class=\"n\">k_0</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">serial</span><span class=\"p\">(</span><span class=\"mi\">32</span><span class=\"p\">):</span>\n",
              "                    <span class=\"k\">for</span> <span class=\"n\">k_1</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">unroll</span><span class=\"p\">(</span><span class=\"mi\">4</span><span class=\"p\">):</span>\n",
              "                        <span class=\"k\">for</span> <span class=\"n\">j_1</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">serial</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">):</span>\n",
              "                            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y_update&quot;</span><span class=\"p\">):</span>\n",
              "                                <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
              "                                <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">j_1</span><span class=\"p\">)</span>\n",
              "                                <span class=\"n\">vk</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">reduce</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">k_0</span> <span class=\"o\">*</span> <span class=\"mi\">4</span> <span class=\"o\">+</span> <span class=\"n\">k_1</span><span class=\"p\">)</span>\n",
              "                                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
              "                <span class=\"k\">for</span> <span class=\"n\">ax0</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">vectorized</span><span class=\"p\">(</span><span class=\"mi\">8</span><span class=\"p\">):</span>\n",
              "                    <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C&quot;</span><span class=\"p\">):</span>\n",
              "                        <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">])</span>\n",
              "                        <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">spatial</span><span class=\"p\">(</span><span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"n\">j_0</span> <span class=\"o\">*</span> <span class=\"mi\">8</span> <span class=\"o\">+</span> <span class=\"n\">ax0</span><span class=\"p\">)</span>\n",
              "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
              "                        <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">))</span>\n",
              "    \n",
              "</pre></div>\n"
            ],
            "text/latex": "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n\\PY{n+nd}{@tvm}\\PY{o}{.}\\PY{n}{script}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n    \\PY{k}{def} \\PY{n+nf}{bmm\\PYZus{}relu}\\PY{p}{(}\\PY{n}{A}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{C}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{k+kc}{None}\\PY{p}{:}\n        \\PY{c+c1}{\\PYZsh{} function attr dict}\n        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{bmm\\PYZus{}relu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n        \\PY{c+c1}{\\PYZsh{} body}\n        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n        \\PY{n}{Y} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{]}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n        \\PY{k}{for} \\PY{n}{n} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{parallel}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{)}\\PY{p}{:}\n            \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{16}\\PY{p}{)}\\PY{p}{:}\n                \\PY{k}{for} \\PY{n}{j\\PYZus{}1\\PYZus{}init} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{vectorized}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y\\PYZus{}init}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                        \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{]}\\PY{p}{)}\n                        \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{8} \\PY{o}{+} \\PY{n}{j\\PYZus{}1\\PYZus{}init}\\PY{p}{)}\n                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{p}{)}\n                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                        \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\n                \\PY{k}{for} \\PY{n}{k\\PYZus{}0} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{serial}\\PY{p}{(}\\PY{l+m+mi}{32}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{k}{for} \\PY{n}{k\\PYZus{}1} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{unroll}\\PY{p}{(}\\PY{l+m+mi}{4}\\PY{p}{)}\\PY{p}{:}\n                        \\PY{k}{for} \\PY{n}{j\\PYZus{}1} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{serial}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{)}\\PY{p}{:}\n                            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y\\PYZus{}update}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                                \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{]}\\PY{p}{)}\n                                \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{8} \\PY{o}{+} \\PY{n}{j\\PYZus{}1}\\PY{p}{)}\n                                \\PY{n}{vk} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{reduce}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{k\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{4} \\PY{o}{+} \\PY{n}{k\\PYZus{}1}\\PY{p}{)}\n                                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]} \\PY{o}{*} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\n                \\PY{k}{for} \\PY{n}{ax0} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{vectorized}\\PY{p}{(}\\PY{l+m+mi}{8}\\PY{p}{)}\\PY{p}{:}\n                    \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{C}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n                        \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{]}\\PY{p}{)}\n                        \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{spatial}\\PY{p}{(}\\PY{l+m+mi}{128}\\PY{p}{,} \\PY{n}{j\\PYZus{}0} \\PY{o}{*} \\PY{l+m+mi}{8} \\PY{o}{+} \\PY{n}{ax0}\\PY{p}{)}\n                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                        \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n                        \\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{)}\n    \n\\end{Verbatim}\n"
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before_rt_lib = tvm.build(MyBmmRelu, target=\"llvm\")\n",
        "after_rt_lib = tvm.build(sch.mod, target=\"llvm\")\n",
        "a_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "b_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "c_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
        "after_rt_lib[\"bmm_relu\"](a_tvm, b_tvm, c_tvm)\n",
        "before_timer = before_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
        "print(\"Before transformation:\")\n",
        "print(before_timer(a_tvm, b_tvm, c_tvm))\n",
        "\n",
        "f_timer = after_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
        "print(\"After transformation:\")\n",
        "print(f_timer(a_tvm, b_tvm, c_tvm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxEAlszcsCMs",
        "outputId": "e3d466a8-6521-45aa-bb7e-7170f76aa14f"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before transformation:\n",
            "Execution time summary:\n",
            " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
            "  53.1903      53.1903      53.1903      53.1903       0.0000   \n",
            "               \n",
            "After transformation:\n",
            "Execution time summary:\n",
            " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
            "  15.2437      15.2437      15.2437      15.2437       0.0000   \n",
            "               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "epE6eJd3vK7y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}